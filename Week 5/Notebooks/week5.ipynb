{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d3347a04",
      "metadata": {
        "id": "d3347a04"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sprince0031/ICT-Python-ML/blob/main/Week%205/Notebooks/week5.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "# Python and ML Foundations: Session 5\n",
        "## Perceptrons, MLPs & Neural Networks\n",
        "\n",
        "Welcome to the session 5 tutorial and companion notebook! In this session, we dive deep into neural networks, starting with perceptrons, building up to multi-layer perceptrons (MLPs), and exploring advanced evaluation metrics. You'll apply these concepts to solve a real-world classification problem."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e11ccf6",
      "metadata": {
        "id": "9e11ccf6"
      },
      "source": [
        "## Utility code\n",
        "The below code cell(s) contain(s) any common imports or sample data that can be useful for your exercises. Make sure to run these cells first before starting your exercises!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baeb0315",
      "metadata": {
        "id": "baeb0315"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "768843ce",
      "metadata": {
        "id": "768843ce"
      },
      "source": [
        "Run below cell to download the Breast Cancer Wisconsin dataset directly from scikit-learn and load it into a Pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce509fd8",
      "metadata": {
        "id": "ce509fd8"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load the breast cancer dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "# Map target values to meaningful labels\n",
        "df['diagnosis'] = df['target'].map({0: 'malignant', 1: 'benign'})\n",
        "\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nFirst few rows:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32902941",
      "metadata": {
        "id": "32902941"
      },
      "source": [
        "---\n",
        "# Video Challenges\n",
        "## About the Breast Cancer Wisconsin Dataset\n",
        "\n",
        "This dataset contains features computed from digitized images of fine needle aspirate (FNA) of breast masses. The features describe characteristics of the cell nuclei present in the images. This is a binary classification problem where the goal is to predict whether a tumor is **malignant** (cancerous) or **benign** (non-cancerous).\n",
        "\n",
        "**Dataset characteristics:**\n",
        "- **569 samples** (212 malignant, 357 benign)\n",
        "- **30 numerical features** including:\n",
        "  - radius, texture, perimeter, area, smoothness\n",
        "  - compactness, concavity, concave points, symmetry, fractal dimension\n",
        "  - Each feature has mean, standard error, and \"worst\" (largest) values\n",
        "- **Target**: 0 = malignant, 1 = benign\n",
        "\n",
        "**Real-world context:**\n",
        "This is a classic medical diagnosis problem where accurate classification can help doctors make informed decisions about treatment. In this context:\n",
        "- **False Negatives** (predicting benign when it's malignant) are very dangerous\n",
        "- **False Positives** (predicting malignant when it's benign) cause unnecessary stress and procedures\n",
        "- We need to carefully balance precision and recall\n",
        "\n",
        "Let's explore this dataset and build increasingly sophisticated models to solve this important classification task!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "video1_section",
      "metadata": {
        "id": "video1_section"
      },
      "source": [
        "---\n",
        "## Video 1: Perceptron & MLPs\n",
        "\n",
        "### Challenge: Build Your First Neural Network Classifier\n",
        "\n",
        "In this challenge, you'll build and compare two classifiers for breast cancer detection:\n",
        "1. A simple **Perceptron** model\n",
        "2. A **Multi-Layer Perceptron (MLP)** with hidden layers\n",
        "\n",
        "**Your tasks:**\n",
        "1. Prepare the data by selecting appropriate features and scaling them\n",
        "2. Split the data into training and testing sets\n",
        "3. Train a Perceptron model and evaluate its accuracy\n",
        "4. Train an MLP model with at least one hidden layer and compare its performance\n",
        "5. Analyze which model performs better and why\n",
        "\n",
        "**Hints:**\n",
        "- Use features like 'mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness' to start\n",
        "- Remember to scale your features using `StandardScaler` - neural networks are sensitive to feature scales\n",
        "- For the MLP, try starting with a simple architecture like `(10,)` or `(20, 10)`\n",
        "- Use `activation='relu'` for the MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video1_ex1",
      "metadata": {
        "id": "video1_ex1"
      },
      "outputs": [],
      "source": [
        "# Step 1: Select features and target\n",
        "# Choose at least 5 features from the dataset\n",
        "# Hint: You can use all 30 features or select specific ones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video1_ex2",
      "metadata": {
        "id": "video1_ex2"
      },
      "outputs": [],
      "source": [
        "# Step 2: Split the data into training and testing sets\n",
        "# Use test_size=0.3 and random_state=42\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video1_ex3",
      "metadata": {
        "id": "video1_ex3"
      },
      "outputs": [],
      "source": [
        "# Step 3: Scale the features using StandardScaler\n",
        "# Remember to fit_transform on training data and transform on test data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video1_ex4",
      "metadata": {
        "id": "video1_ex4"
      },
      "outputs": [],
      "source": [
        "# Step 4: Train a Perceptron model\n",
        "# Use max_iter=1000 and random_state=42\n",
        "# Make predictions and calculate accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video1_ex5",
      "metadata": {
        "id": "video1_ex5"
      },
      "outputs": [],
      "source": [
        "# Step 5: Train an MLP model\n",
        "# Use hidden_layer_sizes of your choice (e.g., (20, 10))\n",
        "# Use activation='relu', max_iter=1000, random_state=42\n",
        "# Make predictions and calculate accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video1_ex6",
      "metadata": {
        "id": "video1_ex6"
      },
      "outputs": [],
      "source": [
        "# Step 6: Compare the two models\n",
        "# Print the accuracy of both models and discuss which performs better\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "video2_section",
      "metadata": {
        "id": "video2_section"
      },
      "source": [
        "---\n",
        "## Video 2: MLPs 2 & Advanced Metrics\n",
        "\n",
        "### Challenge: Evaluate with Advanced Metrics\n",
        "\n",
        "Accuracy alone doesn't tell the whole story, especially in medical diagnosis where the cost of different types of errors varies significantly. In this challenge, you'll evaluate your breast cancer classifier using advanced metrics.\n",
        "\n",
        "**Your tasks:**\n",
        "1. Train an MLP classifier on the breast cancer dataset\n",
        "2. Calculate and compare multiple evaluation metrics:\n",
        "   - Accuracy\n",
        "   - Precision\n",
        "   - Recall\n",
        "   - F1-Score\n",
        "3. Create and visualize a confusion matrix\n",
        "4. Generate a classification report\n",
        "5. Analyze the results in the medical context:\n",
        "   - What do False Positives mean for patients?\n",
        "   - What do False Negatives mean for patients?\n",
        "   - Which metric is most important for this use case?\n",
        "\n",
        "**Hints:**\n",
        "- Use an MLP with architecture like `(50, 25)` or `(30, 20, 10)`\n",
        "- Remember that for this binary classification: class 0 = malignant, class 1 = benign\n",
        "- Use `sns.heatmap()` to visualize the confusion matrix\n",
        "- Consider which is worse: missing a malignant tumor (False Negative) or unnecessary concern (False Positive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video2_ex1",
      "metadata": {
        "id": "video2_ex1"
      },
      "outputs": [],
      "source": [
        "# Step 1: Prepare the data (you can reuse code from Video 1 or start fresh)\n",
        "# Select features, split, and scale\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video2_ex2",
      "metadata": {
        "id": "video2_ex2"
      },
      "outputs": [],
      "source": [
        "# Step 2: Train an MLP classifier\n",
        "# Use a deeper architecture and make predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video2_ex3",
      "metadata": {
        "id": "video2_ex3"
      },
      "outputs": [],
      "source": [
        "# Step 3: Calculate and print multiple metrics\n",
        "# Calculate accuracy, precision, recall, and f1-score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video2_ex4",
      "metadata": {
        "id": "video2_ex4"
      },
      "outputs": [],
      "source": [
        "# Step 4: Create and visualize the confusion matrix\n",
        "# Use confusion_matrix() and sns.heatmap() for visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video2_ex5",
      "metadata": {
        "id": "video2_ex5"
      },
      "outputs": [],
      "source": [
        "# Step 5: Generate a detailed classification report\n",
        "# Use classification_report() with target_names=['malignant', 'benign']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "video3_section",
      "metadata": {
        "id": "video3_section"
      },
      "source": [
        "---\n",
        "## Video 3: Neural Networks Deep Dive\n",
        "\n",
        "### Challenge: Optimize Your Neural Network\n",
        "\n",
        "Now that you understand how neural networks learn, it's time to build an optimized classifier by experimenting with different hyperparameters. Your goal is to create the best possible breast cancer classifier.\n",
        "\n",
        "**Your tasks:**\n",
        "1. Experiment with different MLP architectures (number of layers and neurons)\n",
        "2. Test different activation functions ('relu', 'tanh', 'logistic')\n",
        "3. Try different solvers ('adam', 'sgd', 'lbfgs')\n",
        "4. Experiment with regularization (alpha parameter) to prevent overfitting\n",
        "5. Build a final optimized model using the best combination of hyperparameters\n",
        "6. Evaluate your optimized model using all metrics learned in Video 2\n",
        "\n",
        "**Hints:**\n",
        "- Try architectures like: `(30,)`, `(50, 25)`, `(100, 50, 25)`, `(50, 30, 20, 10)`\n",
        "- Common alpha values to try: `0.0001`, `0.001`, `0.01`, `0.1`\n",
        "- Use `early_stopping=True` and `validation_fraction=0.1` to prevent overfitting\n",
        "- Keep track of both training and test accuracy to detect overfitting\n",
        "- The best model should have high recall (to catch malignant cases) while maintaining good precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video3_ex1",
      "metadata": {
        "id": "video3_ex1"
      },
      "outputs": [],
      "source": [
        "# Step 1: Prepare the data\n",
        "# Use all 30 features for best results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video3_ex2",
      "metadata": {
        "id": "video3_ex2"
      },
      "outputs": [],
      "source": [
        "# Step 2: Experiment with different architectures\n",
        "# Try at least 3 different architectures and compare their performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video3_ex3",
      "metadata": {
        "id": "video3_ex3"
      },
      "outputs": [],
      "source": [
        "# Step 3: Compare different activation functions\n",
        "# Test 'relu', 'tanh', and 'logistic' with the same architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video3_ex4",
      "metadata": {
        "id": "video3_ex4"
      },
      "outputs": [],
      "source": [
        "# Step 4: Experiment with different solvers\n",
        "# Compare 'adam', 'sgd', and 'lbfgs'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video3_ex5",
      "metadata": {
        "id": "video3_ex5"
      },
      "outputs": [],
      "source": [
        "# Step 5: Test different regularization strengths\n",
        "# Try different alpha values and check for overfitting\n",
        "# Compare training accuracy vs test accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video3_ex6",
      "metadata": {
        "id": "video3_ex6"
      },
      "outputs": [],
      "source": [
        "# Step 6: Build your final optimized model\n",
        "# Use the best hyperparameters you found from your experiments\n",
        "# Include: optimal architecture, activation, solver, alpha, early_stopping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video3_ex7",
      "metadata": {
        "id": "video3_ex7"
      },
      "outputs": [],
      "source": [
        "# Step 7: Comprehensive evaluation of your optimized model\n",
        "# Calculate all metrics: accuracy, precision, recall, f1-score\n",
        "# Create confusion matrix and classification report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conclusion",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "---\n",
        "## Reflection Questions\n",
        "\n",
        "After completing all three challenges, consider:\n",
        "\n",
        "1. **Model Evolution**: How did the performance improve from the simple Perceptron to the optimized MLP?\n",
        "\n",
        "2. **Medical Context**: \n",
        "   - What is the cost of a False Negative (missing a malignant tumor)?\n",
        "   - What is the cost of a False Positive (incorrectly predicting malignant)?\n",
        "   - Should you optimize for precision or recall in this scenario?\n",
        "\n",
        "3. **Hyperparameter Impact**: Which hyperparameters had the biggest impact on model performance?\n",
        "\n",
        "4. **Overfitting**: Did you observe any signs of overfitting? How did regularization help?\n",
        "\n",
        "5. **Real-world Deployment**: Would you be comfortable deploying your final model in a clinical setting? What additional steps would you take before deployment?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
