{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d3347a04",
      "metadata": {
        "id": "d3347a04"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sprince0031/ICT-Python-ML/blob/main/Week%205/Notebooks/week5_solutions.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "# Python and ML Foundations: Session 5\n",
        "## Perceptrons, MLPs & Neural Networks - Solutions\n",
        "\n",
        "Welcome to the session 5 solutions notebook! This notebook contains complete solutions to all the challenges from week 5."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e11ccf6",
      "metadata": {
        "id": "9e11ccf6"
      },
      "source": [
        "## Utility code\n",
        "The below code cell(s) contain(s) any common imports or sample data that can be useful for your exercises. Make sure to run these cells first before starting your exercises!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baeb0315",
      "metadata": {
        "id": "baeb0315"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "768843ce",
      "metadata": {
        "id": "768843ce"
      },
      "source": [
        "Run below cell to download the Breast Cancer Wisconsin dataset directly from scikit-learn and load it into a Pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce509fd8",
      "metadata": {
        "id": "ce509fd8"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load the breast cancer dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "# Map target values to meaningful labels\n",
        "df['diagnosis'] = df['target'].map({0: 'malignant', 1: 'benign'})\n",
        "\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nFirst few rows:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32902941",
      "metadata": {
        "id": "32902941"
      },
      "source": [
        "---\n",
        "# Video Challenges\n",
        "## About the Breast Cancer Wisconsin Dataset\n",
        "\n",
        "This dataset contains features computed from digitized images of fine needle aspirate (FNA) of breast masses. The features describe characteristics of the cell nuclei present in the images. This is a binary classification problem where the goal is to predict whether a tumor is **malignant** (cancerous) or **benign** (non-cancerous).\n",
        "\n",
        "**Dataset characteristics:**\n",
        "- **569 samples** (212 malignant, 357 benign)\n",
        "- **30 numerical features** including:\n",
        "  - radius, texture, perimeter, area, smoothness\n",
        "  - compactness, concavity, concave points, symmetry, fractal dimension\n",
        "  - Each feature has mean, standard error, and \"worst\" (largest) values\n",
        "- **Target**: 0 = malignant, 1 = benign\n",
        "\n",
        "**Real-world context:**\n",
        "This is a classic medical diagnosis problem where accurate classification can help doctors make informed decisions about treatment. In this context:\n",
        "- **False Negatives** (predicting benign when it's malignant) are very dangerous\n",
        "- **False Positives** (predicting malignant when it's benign) cause unnecessary stress and procedures\n",
        "- We need to carefully balance precision and recall\n",
        "\n",
        "Let's explore this dataset and build increasingly sophisticated models to solve this important classification task!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "video1_section",
      "metadata": {
        "id": "video1_section"
      },
      "source": [
        "---\n",
        "## Video 1: Perceptron & MLPs\n",
        "\n",
        "### Challenge: Build Your First Neural Network Classifier\n",
        "\n",
        "In this challenge, you'll build and compare two classifiers for breast cancer detection:\n",
        "1. A simple **Perceptron** model\n",
        "2. A **Multi-Layer Perceptron (MLP)** with hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video1_ex1",
      "metadata": {
        "id": "video1_ex1"
      },
      "outputs": [],
      "source": [
        "# Step 1: Select features and target\n",
        "# We'll use all 30 features for comprehensive analysis\n",
        "X = df[data.feature_names]\n",
        "y = df['target']\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"\\nTarget distribution:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video1_ex2",
      "metadata": {
        "id": "video1_ex2"
      },
      "outputs": [],
      "source": [
        "# Step 2: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video1_ex3",
      "metadata": {
        "id": "video1_ex3"
      },
      "outputs": [],
      "source": [
        "# Step 3: Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Features scaled successfully!\")\n",
        "print(f\"Mean of scaled training data: {X_train_scaled.mean():.4f}\")\n",
        "print(f\"Std of scaled training data: {X_train_scaled.std():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video1_ex4",
      "metadata": {
        "id": "video1_ex4"
      },
      "outputs": [],
      "source": [
        "# Step 4: Train a Perceptron model\n",
        "perceptron = Perceptron(max_iter=1000, random_state=42)\n",
        "perceptron.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_perceptron = perceptron.predict(X_test_scaled)\n",
        "\n",
        "# Calculate accuracy\n",
        "acc_perceptron = accuracy_score(y_test, y_pred_perceptron)\n",
        "print(f\"Perceptron Accuracy: {acc_perceptron:.4f}\")\n",
        "print(f\"Number of iterations: {perceptron.n_iter_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video1_ex5",
      "metadata": {
        "id": "video1_ex5"
      },
      "outputs": [],
      "source": [
        "# Step 5: Train an MLP model\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(20, 10), activation='relu', \n",
        "                    max_iter=1000, random_state=42)\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_mlp = mlp.predict(X_test_scaled)\n",
        "\n",
        "# Calculate accuracy\n",
        "acc_mlp = accuracy_score(y_test, y_pred_mlp)\n",
        "print(f\"MLP Accuracy: {acc_mlp:.4f}\")\n",
        "print(f\"Number of layers: {mlp.n_layers_}\")\n",
        "print(f\"Number of iterations: {mlp.n_iter_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video1_ex6",
      "metadata": {
        "id": "video1_ex6"
      },
      "outputs": [],
      "source": [
        "# Step 6: Compare the two models\n",
        "print(\"Model Comparison:\")\n",
        "print(f\"  Perceptron Accuracy: {acc_perceptron:.4f}\")\n",
        "print(f\"  MLP Accuracy:        {acc_mlp:.4f}\")\n",
        "print(f\"\\nImprovement with MLP: {(acc_mlp - acc_perceptron) * 100:.2f}%\")\n",
        "\n",
        "# Visualize comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "models = ['Perceptron', 'MLP']\n",
        "accuracies = [acc_perceptron, acc_mlp]\n",
        "bars = plt.bar(models, accuracies, color=['#3498db', '#2ecc71'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Comparison: Perceptron vs MLP')\n",
        "plt.ylim([0.9, 1.0])\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, acc in zip(bars, accuracies):\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{acc:.4f}',\n",
        "            ha='center', va='bottom')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nAnalysis:\")\n",
        "print(\"The MLP performs better than the simple Perceptron because:\")\n",
        "print(\"1. It can learn non-linear patterns through hidden layers\")\n",
        "print(\"2. Multiple layers allow for more complex feature combinations\")\n",
        "print(\"3. The ReLU activation introduces non-linearity\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "video2_section",
      "metadata": {
        "id": "video2_section"
      },
      "source": [
        "---\n",
        "## Video 2: MLPs 2 & Advanced Metrics\n",
        "\n",
        "### Challenge: Evaluate with Advanced Metrics\n",
        "\n",
        "Accuracy alone doesn't tell the whole story, especially in medical diagnosis where the cost of different types of errors varies significantly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video2_ex1",
      "metadata": {
        "id": "video2_ex1"
      },
      "outputs": [],
      "source": [
        "# Step 1: Prepare the data (reusing from Video 1)\n",
        "# Data is already prepared: X_train_scaled, X_test_scaled, y_train, y_test\n",
        "print(\"Data already prepared from Video 1\")\n",
        "print(f\"Training samples: {X_train_scaled.shape[0]}\")\n",
        "print(f\"Test samples: {X_test_scaled.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video2_ex2",
      "metadata": {
        "id": "video2_ex2"
      },
      "outputs": [],
      "source": [
        "# Step 2: Train an MLP classifier with a deeper architecture\n",
        "mlp_deep = MLPClassifier(hidden_layer_sizes=(50, 25), activation='relu',\n",
        "                         max_iter=1000, random_state=42)\n",
        "mlp_deep.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = mlp_deep.predict(X_test_scaled)\n",
        "\n",
        "print(f\"Model trained successfully!\")\n",
        "print(f\"Architecture: {mlp_deep.hidden_layer_sizes}\")\n",
        "print(f\"Training iterations: {mlp_deep.n_iter_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video2_ex3",
      "metadata": {
        "id": "video2_ex3"
      },
      "outputs": [],
      "source": [
        "# Step 3: Calculate and print multiple metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"MODEL PERFORMANCE METRICS\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}  (Of all predicted benign, how many are correct?)\")\n",
        "print(f\"Recall:    {recall:.4f}  (Of all actual benign cases, how many did we find?)\")\n",
        "print(f\"F1-Score:  {f1:.4f}  (Harmonic mean of precision and recall)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Visualize metrics\n",
        "plt.figure(figsize=(10, 6))\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "values = [accuracy, precision, recall, f1]\n",
        "colors = ['#3498db', '#2ecc71', '#e74c3c', '#f39c12']\n",
        "bars = plt.bar(metrics, values, color=colors)\n",
        "plt.ylabel('Score')\n",
        "plt.title('Comprehensive Model Evaluation')\n",
        "plt.ylim([0.9, 1.0])\n",
        "\n",
        "for bar, val in zip(bars, values):\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{val:.4f}',\n",
        "            ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video2_ex4",
      "metadata": {
        "id": "video2_ex4"
      },
      "outputs": [],
      "source": [
        "# Step 4: Create and visualize the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['Malignant (0)', 'Benign (1)'],\n",
        "            yticklabels=['Malignant (0)', 'Benign (1)'],\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.title('Confusion Matrix - Breast Cancer Classification', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CONFUSION MATRIX BREAKDOWN\")\n",
        "print(\"=\"*50)\n",
        "print(f\"True Negatives (TN):  {cm[0, 0]:3d}  - Correctly identified malignant\")\n",
        "print(f\"False Positives (FP): {cm[0, 1]:3d}  - Benign predicted as malignant (unnecessary concern)\")\n",
        "print(f\"False Negatives (FN): {cm[1, 0]:3d}  - Malignant predicted as benign (DANGEROUS!)\")\n",
        "print(f\"True Positives (TP):  {cm[1, 1]:3d}  - Correctly identified benign\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\\nMedical Context Analysis:\")\n",
        "print(f\"- False Negatives ({cm[1, 0]}): Missing malignant tumors is life-threatening\")\n",
        "print(f\"- False Positives ({cm[0, 1]}): Cause unnecessary stress and procedures\")\n",
        "print(f\"- In medical diagnosis, minimizing False Negatives is critical\")\n",
        "print(f\"- High Recall ({recall:.4f}) means we're catching most malignant cases\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video2_ex5",
      "metadata": {
        "id": "video2_ex5"
      },
      "outputs": [],
      "source": [
        "# Step 5: Generate a detailed classification report\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DETAILED CLASSIFICATION REPORT\")\n",
        "print(\"=\"*70)\n",
        "print(classification_report(y_test, y_pred, \n",
        "                          target_names=['Malignant (0)', 'Benign (1)']))\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nKey Insights:\")\n",
        "print(\"1. Support: Number of samples in each class\")\n",
        "print(\"2. For malignant cases (class 0):\")\n",
        "print(\"   - High precision means low false alarms\")\n",
        "print(\"   - High recall means we're catching most malignant cases\")\n",
        "print(\"3. For benign cases (class 1):\")\n",
        "print(\"   - High precision means confident benign predictions\")\n",
        "print(\"   - High recall means we're correctly identifying benign cases\")\n",
        "print(\"4. In this medical context, we want:\")\n",
        "print(\"   - Very high recall for malignant (class 0) - don't miss cancers\")\n",
        "print(\"   - Good precision overall - minimize false alarms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "video3_section",
      "metadata": {
        "id": "video3_section"
      },
      "source": [
        "---\n",
        "## Video 3: Neural Networks Deep Dive\n",
        "\n",
        "### Challenge: Optimize Your Neural Network\n",
        "\n",
        "Now that you understand how neural networks learn, it's time to build an optimized classifier by experimenting with different hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video3_ex1",
      "metadata": {
        "id": "video3_ex1"
      },
      "outputs": [],
      "source": [
        "# Step 1: Prepare the data (already done)\n",
        "print(\"Using the same prepared dataset from previous sections\")\n",
        "print(f\"Features: {X_train_scaled.shape[1]}\")\n",
        "print(f\"Training samples: {X_train_scaled.shape[0]}\")\n",
        "print(f\"Test samples: {X_test_scaled.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video3_ex2",
      "metadata": {
        "id": "video3_ex2"
      },
      "outputs": [],
      "source": [
        "# Step 2: Experiment with different architectures\n",
        "architectures = [\n",
        "    (30,),\n",
        "    (50, 25),\n",
        "    (100, 50, 25),\n",
        "    (50, 30, 20, 10)\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ARCHITECTURE COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "arch_results = []\n",
        "for arch in architectures:\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=arch, activation='relu',\n",
        "                       max_iter=1000, random_state=42)\n",
        "    mlp.fit(X_train_scaled, y_train)\n",
        "    y_pred = mlp.predict(X_test_scaled)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    arch_results.append({'architecture': arch, 'accuracy': acc})\n",
        "    print(f\"Architecture {str(arch):20s}: Accuracy = {acc:.4f}\")\n",
        "\n",
        "best_arch = max(arch_results, key=lambda x: x['accuracy'])\n",
        "print(f\"\\nBest Architecture: {best_arch['architecture']} with accuracy {best_arch['accuracy']:.4f}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video3_ex3",
      "metadata": {
        "id": "video3_ex3"
      },
      "outputs": [],
      "source": [
        "# Step 3: Compare different activation functions\n",
        "activations = ['relu', 'tanh', 'logistic']\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ACTIVATION FUNCTION COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "activation_results = []\n",
        "for activation in activations:\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=(50, 25), activation=activation,\n",
        "                       max_iter=1000, random_state=42)\n",
        "    mlp.fit(X_train_scaled, y_train)\n",
        "    y_pred = mlp.predict(X_test_scaled)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    activation_results.append(acc)\n",
        "    print(f\"Activation: {activation:10s} - Accuracy: {acc:.4f}\")\n",
        "\n",
        "best_activation_idx = np.argmax(activation_results)\n",
        "print(f\"\\nBest Activation: {activations[best_activation_idx]} with accuracy {activation_results[best_activation_idx]:.4f}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video3_ex4",
      "metadata": {
        "id": "video3_ex4"
      },
      "outputs": [],
      "source": [
        "# Step 4: Experiment with different solvers\n",
        "solvers = ['adam', 'sgd', 'lbfgs']\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SOLVER COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "solver_results = []\n",
        "for solver in solvers:\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=(50, 25), activation='relu',\n",
        "                       solver=solver, max_iter=1000, random_state=42)\n",
        "    mlp.fit(X_train_scaled, y_train)\n",
        "    y_pred = mlp.predict(X_test_scaled)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    solver_results.append(acc)\n",
        "    print(f\"Solver: {solver:8s} - Accuracy: {acc:.4f}, Iterations: {mlp.n_iter_}\")\n",
        "\n",
        "best_solver_idx = np.argmax(solver_results)\n",
        "print(f\"\\nBest Solver: {solvers[best_solver_idx]} with accuracy {solver_results[best_solver_idx]:.4f}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video3_ex5",
      "metadata": {
        "id": "video3_ex5"
      },
      "outputs": [],
      "source": [
        "# Step 5: Test different regularization strengths\n",
        "alphas = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"REGULARIZATION (ALPHA) COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for alpha in alphas:\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=(100, 50, 25), activation='relu',\n",
        "                       alpha=alpha, max_iter=1000, random_state=42)\n",
        "    mlp.fit(X_train_scaled, y_train)\n",
        "    \n",
        "    train_acc = mlp.score(X_train_scaled, y_train)\n",
        "    test_acc = mlp.score(X_test_scaled, y_test)\n",
        "    gap = train_acc - test_acc\n",
        "    \n",
        "    print(f\"Alpha {alpha:7.4f}: Train={train_acc:.4f}, Test={test_acc:.4f}, Gap={gap:.4f}\")\n",
        "\n",
        "print(\"\\nAnalysis:\")\n",
        "print(\"- Small gap indicates good generalization (less overfitting)\")\n",
        "print(\"- Too much regularization can cause underfitting (lower test accuracy)\")\n",
        "print(\"- Alpha around 0.001-0.01 typically provides good balance\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video3_ex6",
      "metadata": {
        "id": "video3_ex6"
      },
      "outputs": [],
      "source": [
        "# Step 6: Build the final optimized model\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BUILDING OPTIMIZED MODEL\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "mlp_optimized = MLPClassifier(\n",
        "    hidden_layer_sizes=(100, 50, 25),  # Deep architecture for complex patterns\n",
        "    activation='relu',                  # Best performing activation\n",
        "    solver='adam',                      # Adaptive learning rate\n",
        "    alpha=0.001,                       # Moderate regularization\n",
        "    batch_size=32,                     # Mini-batch for stable gradients\n",
        "    learning_rate_init=0.001,          # Moderate learning rate\n",
        "    max_iter=1000,\n",
        "    early_stopping=True,               # Prevent overfitting\n",
        "    validation_fraction=0.1,           # 10% for validation\n",
        "    random_state=42,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "mlp_optimized.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(f\"Training completed in {mlp_optimized.n_iter_} iterations\")\n",
        "print(f\"Final training loss: {mlp_optimized.loss_:.6f}\")\n",
        "print(\"\\nModel Configuration:\")\n",
        "print(f\"  Architecture: {mlp_optimized.hidden_layer_sizes}\")\n",
        "print(f\"  Activation: {mlp_optimized.activation}\")\n",
        "print(f\"  Solver: {mlp_optimized.solver}\")\n",
        "print(f\"  Alpha (L2): {mlp_optimized.alpha}\")\n",
        "print(f\"  Batch size: {mlp_optimized.batch_size}\")\n",
        "print(f\"  Learning rate: {mlp_optimized.learning_rate_init}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "video3_ex7",
      "metadata": {
        "id": "video3_ex7"
      },
      "outputs": [],
      "source": [
        "# Step 7: Comprehensive evaluation of the optimized model\n",
        "y_pred_optimized = mlp_optimized.predict(X_test_scaled)\n",
        "\n",
        "# Calculate all metrics\n",
        "accuracy_opt = accuracy_score(y_test, y_pred_optimized)\n",
        "precision_opt = precision_score(y_test, y_pred_optimized)\n",
        "recall_opt = recall_score(y_test, y_pred_optimized)\n",
        "f1_opt = f1_score(y_test, y_pred_optimized)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"OPTIMIZED MODEL - FINAL EVALUATION\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Accuracy:  {accuracy_opt:.4f}\")\n",
        "print(f\"Precision: {precision_opt:.4f}\")\n",
        "print(f\"Recall:    {recall_opt:.4f}\")\n",
        "print(f\"F1-Score:  {f1_opt:.4f}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Confusion matrix\n",
        "cm_opt = confusion_matrix(y_test, y_pred_optimized)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Plot 1: Confusion Matrix\n",
        "sns.heatmap(cm_opt, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
        "            xticklabels=['Malignant', 'Benign'],\n",
        "            yticklabels=['Malignant', 'Benign'])\n",
        "axes[0].set_title('Confusion Matrix - Optimized Model', fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylabel('True Label', fontsize=12)\n",
        "axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
        "\n",
        "# Plot 2: Metrics Comparison\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "values = [accuracy_opt, precision_opt, recall_opt, f1_opt]\n",
        "colors = ['#3498db', '#2ecc71', '#e74c3c', '#f39c12']\n",
        "bars = axes[1].bar(metrics, values, color=colors)\n",
        "axes[1].set_ylabel('Score', fontsize=12)\n",
        "axes[1].set_title('All Metrics - Optimized Model', fontsize=14, fontweight='bold')\n",
        "axes[1].set_ylim([0.90, 1.0])\n",
        "\n",
        "for bar, val in zip(bars, values):\n",
        "    height = bar.get_height()\n",
        "    axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{val:.4f}',\n",
        "                ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_optimized, \n",
        "                          target_names=['Malignant', 'Benign']))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CONFUSION MATRIX ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"True Negatives:  {cm_opt[0, 0]:3d} - Correctly identified malignant\")\n",
        "print(f\"False Positives: {cm_opt[0, 1]:3d} - Benign predicted as malignant\")\n",
        "print(f\"False Negatives: {cm_opt[1, 0]:3d} - Malignant predicted as benign (CRITICAL!)\")\n",
        "print(f\"True Positives:  {cm_opt[1, 1]:3d} - Correctly identified benign\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conclusion",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "---\n",
        "## Summary and Insights\n",
        "\n",
        "### Model Evolution:\n",
        "1. **Perceptron**: Simple linear classifier, good baseline but limited by linear decision boundaries\n",
        "2. **Basic MLP**: Significantly better with hidden layers enabling non-linear pattern learning\n",
        "3. **Optimized MLP**: Best performance through careful hyperparameter tuning\n",
        "\n",
        "### Medical Context Considerations:\n",
        "- **False Negatives** (missing malignant tumors) are life-threatening\n",
        "- **False Positives** cause unnecessary stress and procedures\n",
        "- High **Recall** is critical to catch malignant cases\n",
        "- Good **Precision** minimizes false alarms\n",
        "- **F1-Score** provides balanced view of both\n",
        "\n",
        "### Key Hyperparameter Findings:\n",
        "1. **Architecture**: Deeper networks (3-4 layers) perform better\n",
        "2. **Activation**: ReLU consistently outperforms tanh and sigmoid\n",
        "3. **Solver**: Adam optimizer provides best convergence\n",
        "4. **Regularization**: Alpha ~0.001 balances overfitting prevention and performance\n",
        "5. **Early Stopping**: Prevents overfitting by monitoring validation performance\n",
        "\n",
        "### Real-World Deployment Considerations:\n",
        "1. Need larger, more diverse dataset for production\n",
        "2. Should implement cross-validation for robust evaluation\n",
        "3. Require clinical validation and regulatory approval\n",
        "4. Must establish monitoring system for model performance\n",
        "5. Should use ensemble methods for critical decisions\n",
        "6. Need explainability features for doctor interpretation\n",
        "\n",
        "This optimized neural network demonstrates the power of deep learning in medical diagnosis, achieving high accuracy while carefully balancing the critical trade-offs between precision and recall in a life-or-death classification task."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
